# RVC
Reinforcement Learning for Visual Comprehension

# Driving Question
If we give a Reinforcement Learning agent 2 tools: **vision** and **memory** will it be able to scan an image and learn "where to look" 


# Reinforcement Learning:
### 1. Action Space
The action space is defined as such: For a **h** x **w** the action space is each point on the image with a stride of **s** the action space is defined as follows:

image size: $I$ \
patch size: $P$ \
stride: $s$

$$
N = \frac{(I - P)}s\ + 1
$$

Each possible action is a $(x,y)$ coordinate where $x,y \in [0, 1]$ and is sampled from the probability distribution generated by the policy over the action space.  
### 2. Reward
To avoid a sparse reward signal I used two rewards:
1. Final Classification Reward
    $$2 \text{ if } \hat{y} = y \text{ else } -2$$
2. Per Step Confidence Rewards
    $$ \Delta\text{CE} = CE_i - CE_{i-1}, \quad   -0.1 <\Delta\text{CE} < 0.1$$ 
    This will reward the model for taking "informational" glimpses as it rewards an increased cross entropy loss from the previous step encouraging the model to take steps that gain the most information

### 3. Updating
This policy is trained using REINFORCE with a baseline to improve learning stability

# Classification:
1. Using the policy generate an action based on the prevous state; $(x,y)$ center position to extract a patch from.

2. Pass this patch into an encoder (a small CNN or MLP)

3. Pass all current embeddings $e_0-e_t$ into the final (Attention + RNN) + Classifier head block to get current class confidences and compute per step $\Delta CE$ reward

3. Pass this patch embedding into the agents memory (A LSTM) and generate the context vector for the next state

4. Repeat (1-3) for a pre-specified number of steps

5. Concat embeddings $e_0-e_n$ and pass through a (Attention + RNN) -> Classifier to get final class predictions


# Experiments
The following commands show how to replicate a few experiments

```bash
python main.py --pretrain True --patch_size 8 --steps 6 --img_size 64 --clutter_count 4 --stride 4
```

![Demo](/gifs_experiment1/attention1.gif) ![Demo](/gifs_experiment1/attention2.gif) ![Demo](/gifs_experiment1/attention3.gif)

![Demo](/gifs_experiment1/attention4.gif) ![Demo](/gifs_experiment1/attention5.gif) ![Demo](/gifs_experiment1/attention6.gif)

```bash
python main.py --pretrain True --patch_size 4 --steps 6 --img_size 28 --clutter_count 0 --stride 4
```
![Demo](/gifs_experiment2/attention1.gif) ![Demo](/gifs_experiment2/attention2.gif) ![Demo](/gifs_experiment2/attention3.gif)

![Demo](/gifs_experiment2/attention4.gif) ![Demo](/gifs_experiment2/attention5.gif) ![Demo](/gifs_experiment2/attention6.gif)

# References
* https://github.com/bentrevett/recurrent-attention-model